{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7541e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e76556f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, \"live-table\")))\n",
    "\n",
    "    while True:\n",
    "        # Find all current \"Show more\" links\n",
    "        show_more_links = driver.find_elements(By.XPATH, \"//span[contains(text(), 'Show more matches')]/parent::a\")\n",
    "        if not show_more_links:\n",
    "            break  # No more links to click\n",
    "\n",
    "        for link in show_more_links:\n",
    "            try:\n",
    "                # Scroll to the link to ensure it's visible\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", link)\n",
    "                link.click()\n",
    "                # Wait for the link to become stale (content expanded)\n",
    "                WebDriverWait(driver, 5).until(EC.staleness_of(link))\n",
    "            except Exception:\n",
    "                pass  # Ignore if already expanded or error\n",
    "\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42a0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_raw_data('https://www.livesport.com/uk/football/england/premier-league-2023-2024/results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dbd3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = soup.find_all('div', class_='event__match event__match--withRowLink event__match--static event__match--twoLine')\n",
    "last_event = soup.find_all('div', class_='event__match event__match--withRowLink event__match--static event__match--last event__match--twoLine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b6a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"event__time\">12.08. 12:30</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[-1].find('div', class_='event__time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432e7457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(last_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6deee",
   "metadata": {},
   "source": [
    "* The match fixtures are structured in rounds, as if they were individual tables separating the first to the last event of each round\n",
    "* You can use the events variable to get the regular events and the last_event to get the last event of each round respectively\n",
    "* However, despite the data exploration, there seems to be a mismatch between the length of last event and number of rounds. Which is left to be solved\n",
    "* Nonetheless, some progress was made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2376dca",
   "metadata": {},
   "source": [
    "# <h4>Fix the `last_event` length mismatch and craft a function to fully retrieve data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8662089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"event__time\">11.08. 20:00</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_event[-1].find('div', class_='event__time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59df6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = soup.find('div', class_='sportName soccer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7cda97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_div = []\n",
    "for div in ex.find_all('div', recursive=False):\n",
    "    classes = div.get('class')\n",
    "    if not 'event__match' in classes:\n",
    "        continue \n",
    "    all_div.append(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53329a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event__match',\n",
       " 'event__match--withRowLink',\n",
       " 'event__match--static',\n",
       " 'event__match--last',\n",
       " 'event__match--twoLine']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78a761e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Burnley', 'Man City')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_div[-1].find('div', class_='wcl-participant_bctDY event__homeParticipant').text, all_div[-1].find('div', class_='wcl-participant_bctDY event__awayParticipant').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4507c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Burnley'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_div[-1].find('div', class_='wcl-participant_bctDY event__homeParticipant').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d91611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19.05. 16:00',\n",
       " '19.05. 16:00',\n",
       " '19.05. 16:00',\n",
       " '19.05. 16:00',\n",
       " '19.05. 16:00',\n",
       " '19.05. 16:00',\n",
       " '19.05. 16:00',\n",
       " '19.05. 16:00',\n",
       " '19.05. 16:00',\n",
       " '19.05. 16:00',\n",
       " '15.05. 20:00',\n",
       " '15.05. 19:45',\n",
       " '14.05. 20:00',\n",
       " '13.05. 20:00',\n",
       " '12.05. 16:30',\n",
       " '11.05. 17:30',\n",
       " '11.05. 15:00',\n",
       " '11.05. 15:00',\n",
       " '11.05. 15:00',\n",
       " '11.05. 15:00',\n",
       " '11.05. 15:00',\n",
       " '11.05. 15:00',\n",
       " '11.05. 12:30',\n",
       " '06.05. 20:00',\n",
       " '05.05. 16:30',\n",
       " '05.05. 14:00',\n",
       " '05.05. 14:00',\n",
       " '04.05. 17:30',\n",
       " '04.05. 15:00',\n",
       " '04.05. 15:00',\n",
       " '04.05. 15:00',\n",
       " '04.05. 12:30',\n",
       " '03.05. 20:00',\n",
       " '02.05. 19:30',\n",
       " '28.04. 16:30',\n",
       " '28.04. 14:00',\n",
       " '28.04. 14:00',\n",
       " '27.04. 20:00',\n",
       " '27.04. 17:30',\n",
       " '27.04. 15:00',\n",
       " '27.04. 15:00',\n",
       " '27.04. 15:00',\n",
       " '27.04. 15:00',\n",
       " '27.04. 12:30',\n",
       " '25.04. 20:00',\n",
       " '24.04. 20:00',\n",
       " '24.04. 20:00',\n",
       " '24.04. 20:00',\n",
       " '24.04. 19:45',\n",
       " '23.04. 20:00',\n",
       " '21.04. 16:30',\n",
       " '21.04. 15:00',\n",
       " '21.04. 15:00',\n",
       " '21.04. 13:30',\n",
       " '20.04. 19:30',\n",
       " '20.04. 15:00',\n",
       " '20.04. 15:00',\n",
       " '15.04. 20:00',\n",
       " '14.04. 16:30',\n",
       " '14.04. 14:00',\n",
       " '14.04. 14:00',\n",
       " '13.04. 17:30',\n",
       " '13.04. 15:00',\n",
       " '13.04. 15:00',\n",
       " '13.04. 15:00',\n",
       " '13.04. 15:00',\n",
       " '13.04. 12:30',\n",
       " '07.04. 18:00',\n",
       " '07.04. 17:30',\n",
       " '07.04. 15:30',\n",
       " '06.04. 17:30',\n",
       " '06.04. 15:00',\n",
       " '06.04. 15:00',\n",
       " '06.04. 15:00',\n",
       " '06.04. 15:00',\n",
       " '06.04. 15:00',\n",
       " '06.04. 12:30',\n",
       " '04.04. 20:15',\n",
       " '04.04. 19:30',\n",
       " '03.04. 20:15',\n",
       " '03.04. 19:30',\n",
       " '03.04. 19:30',\n",
       " '02.04. 20:15',\n",
       " '02.04. 19:45',\n",
       " '02.04. 19:45',\n",
       " '02.04. 19:30',\n",
       " '02.04. 19:30',\n",
       " '31.03. 16:30',\n",
       " '31.03. 14:00',\n",
       " '30.03. 20:00',\n",
       " '30.03. 17:30',\n",
       " '30.03. 15:00',\n",
       " '30.03. 15:00',\n",
       " '30.03. 15:00',\n",
       " '30.03. 15:00',\n",
       " '30.03. 15:00',\n",
       " '30.03. 12:30',\n",
       " '17.03. 14:00',\n",
       " '16.03. 17:30',\n",
       " '16.03. 15:00',\n",
       " '16.03. 15:00',\n",
       " '13.03. 19:30',\n",
       " '11.03. 20:00',\n",
       " '10.03. 15:45',\n",
       " '10.03. 14:00',\n",
       " '10.03. 14:00',\n",
       " '10.03. 13:00',\n",
       " '09.03. 17:30',\n",
       " '09.03. 15:00',\n",
       " '09.03. 15:00',\n",
       " '09.03. 15:00',\n",
       " '09.03. 12:30',\n",
       " '04.03. 20:00',\n",
       " '03.03. 15:30',\n",
       " '03.03. 13:00',\n",
       " '02.03. 17:30',\n",
       " '02.03. 15:00',\n",
       " '02.03. 15:00',\n",
       " '02.03. 15:00',\n",
       " '02.03. 15:00',\n",
       " '02.03. 15:00',\n",
       " '02.03. 15:00',\n",
       " '26.02. 20:00',\n",
       " '25.02. 13:30',\n",
       " '24.02. 20:00',\n",
       " '24.02. 17:30',\n",
       " '24.02. 15:00',\n",
       " '24.02. 15:00',\n",
       " '24.02. 15:00',\n",
       " '24.02. 15:00',\n",
       " '21.02. 19:30',\n",
       " '20.02. 19:30',\n",
       " '19.02. 20:00',\n",
       " '18.02. 16:30',\n",
       " '18.02. 14:00',\n",
       " '17.02. 17:30',\n",
       " '17.02. 15:00',\n",
       " '17.02. 15:00',\n",
       " '17.02. 15:00',\n",
       " '17.02. 15:00',\n",
       " '17.02. 15:00',\n",
       " '17.02. 12:30',\n",
       " '12.02. 20:00',\n",
       " '11.02. 16:30',\n",
       " '11.02. 14:00',\n",
       " '10.02. 17:30',\n",
       " '10.02. 15:00',\n",
       " '10.02. 15:00',\n",
       " '10.02. 15:00',\n",
       " '10.02. 15:00',\n",
       " '10.02. 15:00',\n",
       " '10.02. 12:30',\n",
       " '05.02. 20:00',\n",
       " '04.02. 16:30',\n",
       " '04.02. 14:00',\n",
       " '04.02. 14:00',\n",
       " '04.02. 14:00',\n",
       " '03.02. 17:30',\n",
       " '03.02. 15:00',\n",
       " '03.02. 15:00',\n",
       " '03.02. 15:00',\n",
       " '03.02. 12:30',\n",
       " '01.02. 20:15',\n",
       " '01.02. 19:30',\n",
       " '31.01. 20:15',\n",
       " '31.01. 19:30',\n",
       " '31.01. 19:30',\n",
       " '30.01. 20:15',\n",
       " '30.01. 20:00',\n",
       " '30.01. 19:45',\n",
       " '30.01. 19:45',\n",
       " '30.01. 19:30',\n",
       " '22.01. 19:45',\n",
       " '21.01. 16:30',\n",
       " '21.01. 14:00',\n",
       " '20.01. 17:30',\n",
       " '20.01. 12:30',\n",
       " '14.01. 16:30',\n",
       " '14.01. 14:00',\n",
       " '13.01. 17:30',\n",
       " '13.01. 12:30',\n",
       " '12.01. 19:45',\n",
       " '02.01. 19:30',\n",
       " '01.01. 20:00',\n",
       " '31.12. 14:00',\n",
       " '31.12. 14:00',\n",
       " '30.12. 17:30',\n",
       " '30.12. 15:00',\n",
       " '30.12. 15:00',\n",
       " '30.12. 15:00',\n",
       " '30.12. 15:00',\n",
       " '30.12. 12:30',\n",
       " '28.12. 20:15',\n",
       " '28.12. 19:30',\n",
       " '27.12. 20:15',\n",
       " '27.12. 19:30',\n",
       " '27.12. 19:30',\n",
       " '26.12. 20:00',\n",
       " '26.12. 17:30',\n",
       " '26.12. 15:00',\n",
       " '26.12. 15:00',\n",
       " '26.12. 12:30',\n",
       " '24.12. 13:00',\n",
       " '23.12. 17:30',\n",
       " '23.12. 15:00',\n",
       " '23.12. 15:00',\n",
       " '23.12. 15:00',\n",
       " '23.12. 15:00',\n",
       " '23.12. 12:30',\n",
       " '22.12. 20:00',\n",
       " '21.12. 20:00',\n",
       " '17.12. 16:30',\n",
       " '17.12. 14:00',\n",
       " '17.12. 14:00',\n",
       " '17.12. 14:00',\n",
       " '16.12. 17:30',\n",
       " '16.12. 15:00',\n",
       " '16.12. 15:00',\n",
       " '16.12. 15:00',\n",
       " '15.12. 20:00',\n",
       " '10.12. 16:30',\n",
       " '10.12. 14:00',\n",
       " '10.12. 14:00',\n",
       " '10.12. 14:00',\n",
       " '09.12. 17:30',\n",
       " '09.12. 15:00',\n",
       " '09.12. 15:00',\n",
       " '09.12. 15:00',\n",
       " '09.12. 15:00',\n",
       " '09.12. 12:30',\n",
       " '07.12. 20:15',\n",
       " '07.12. 19:30',\n",
       " '06.12. 20:15',\n",
       " '06.12. 20:15',\n",
       " '06.12. 19:30',\n",
       " '06.12. 19:30',\n",
       " '06.12. 19:30',\n",
       " '06.12. 19:30',\n",
       " '05.12. 20:15',\n",
       " '05.12. 19:30',\n",
       " '03.12. 16:30',\n",
       " '03.12. 14:00',\n",
       " '03.12. 14:00',\n",
       " '03.12. 14:00',\n",
       " '03.12. 14:00',\n",
       " '02.12. 20:00',\n",
       " '02.12. 17:30',\n",
       " '02.12. 15:00',\n",
       " '02.12. 15:00',\n",
       " '02.12. 15:00',\n",
       " '27.11. 20:00',\n",
       " '26.11. 16:30',\n",
       " '26.11. 14:00',\n",
       " '25.11. 17:30',\n",
       " '25.11. 15:00',\n",
       " '25.11. 15:00',\n",
       " '25.11. 15:00',\n",
       " '25.11. 15:00',\n",
       " '25.11. 15:00',\n",
       " '25.11. 12:30',\n",
       " '12.11. 16:30',\n",
       " '12.11. 14:00',\n",
       " '12.11. 14:00',\n",
       " '12.11. 14:00',\n",
       " '12.11. 14:00',\n",
       " '11.11. 17:30',\n",
       " '11.11. 15:00',\n",
       " '11.11. 15:00',\n",
       " '11.11. 15:00',\n",
       " '11.11. 12:30',\n",
       " '06.11. 20:00',\n",
       " '05.11. 16:30',\n",
       " '05.11. 14:00',\n",
       " '04.11. 17:30',\n",
       " '04.11. 15:00',\n",
       " '04.11. 15:00',\n",
       " '04.11. 15:00',\n",
       " '04.11. 15:00',\n",
       " '04.11. 15:00',\n",
       " '04.11. 12:30',\n",
       " '29.10. 15:30',\n",
       " '29.10. 14:00',\n",
       " '29.10. 14:00',\n",
       " '29.10. 14:00',\n",
       " '29.10. 13:00',\n",
       " '28.10. 17:30',\n",
       " '28.10. 15:00',\n",
       " '28.10. 15:00',\n",
       " '28.10. 12:30',\n",
       " '27.10. 20:00',\n",
       " '23.10. 20:00',\n",
       " '22.10. 16:30',\n",
       " '21.10. 20:00',\n",
       " '21.10. 17:30',\n",
       " '21.10. 15:00',\n",
       " '21.10. 15:00',\n",
       " '21.10. 15:00',\n",
       " '21.10. 15:00',\n",
       " '21.10. 15:00',\n",
       " '21.10. 12:30',\n",
       " '08.10. 16:30',\n",
       " '08.10. 14:00',\n",
       " '08.10. 14:00',\n",
       " '08.10. 14:00',\n",
       " '07.10. 17:30',\n",
       " '07.10. 15:00',\n",
       " '07.10. 15:00',\n",
       " '07.10. 15:00',\n",
       " '07.10. 15:00',\n",
       " '07.10. 12:30',\n",
       " '03.10. 19:30',\n",
       " '02.10. 20:00',\n",
       " '01.10. 14:00',\n",
       " '30.09. 17:30',\n",
       " '30.09. 15:00',\n",
       " '30.09. 15:00',\n",
       " '30.09. 15:00',\n",
       " '30.09. 15:00',\n",
       " '30.09. 15:00',\n",
       " '30.09. 15:00',\n",
       " '30.09. 12:30',\n",
       " '24.09. 16:30',\n",
       " '24.09. 14:00',\n",
       " '24.09. 14:00',\n",
       " '24.09. 14:00',\n",
       " '24.09. 14:00',\n",
       " '23.09. 20:00',\n",
       " '23.09. 17:30',\n",
       " '23.09. 15:00',\n",
       " '23.09. 15:00',\n",
       " '23.09. 15:00',\n",
       " '18.09. 19:45',\n",
       " '17.09. 16:30',\n",
       " '17.09. 14:00',\n",
       " '16.09. 17:30',\n",
       " '16.09. 15:00',\n",
       " '16.09. 15:00',\n",
       " '16.09. 15:00',\n",
       " '16.09. 15:00',\n",
       " '16.09. 15:00',\n",
       " '16.09. 12:30',\n",
       " '03.09. 16:30',\n",
       " '03.09. 14:00',\n",
       " '03.09. 14:00',\n",
       " '02.09. 17:30',\n",
       " '02.09. 15:00',\n",
       " '02.09. 15:00',\n",
       " '02.09. 15:00',\n",
       " '02.09. 15:00',\n",
       " '02.09. 12:30',\n",
       " '01.09. 20:00',\n",
       " '27.08. 16:30',\n",
       " '27.08. 14:00',\n",
       " '27.08. 14:00',\n",
       " '26.08. 17:30',\n",
       " '26.08. 15:00',\n",
       " '26.08. 15:00',\n",
       " '26.08. 15:00',\n",
       " '26.08. 15:00',\n",
       " '26.08. 12:30',\n",
       " '25.08. 20:00',\n",
       " '21.08. 20:00',\n",
       " '20.08. 16:30',\n",
       " '20.08. 14:00',\n",
       " '19.08. 20:00',\n",
       " '19.08. 17:30',\n",
       " '19.08. 15:00',\n",
       " '19.08. 15:00',\n",
       " '19.08. 15:00',\n",
       " '18.08. 19:45',\n",
       " '14.08. 20:00',\n",
       " '13.08. 16:30',\n",
       " '13.08. 14:00',\n",
       " '12.08. 17:30',\n",
       " '12.08. 15:00',\n",
       " '12.08. 15:00',\n",
       " '12.08. 15:00',\n",
       " '12.08. 15:00',\n",
       " '12.08. 12:30',\n",
       " '11.08. 20:00']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = []\n",
    "for match in all_div:\n",
    "    dates.append(match.find('div', class_='event__time').text)\n",
    "\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e499cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches():\n",
    "    # soup = get_raw_data('https://www.livesport.com/uk/football/england/premier-league-2023-2024/results/')\n",
    "    fixtures = soup.find('div', class_='sportName soccer')\n",
    "    all_div = []\n",
    "    for div in fixtures.find_all('div', recursive=False):\n",
    "        classes = div.get('class')\n",
    "        if not 'event__match' in classes:\n",
    "            continue\n",
    "        all_div.append(div)\n",
    "\n",
    "    first_year = 2023\n",
    "    second_year = 2024\n",
    "\n",
    "    season = []\n",
    "    dates = []\n",
    "    for match in all_div:\n",
    "        home_team = match.find('div', class_='wcl-participant_bctDY event__homeParticipant').text\n",
    "        away_team = match.find('div', class_='wcl-participant_bctDY event__awayParticipant').text\n",
    "        date_el = match.find('div', class_='event__time')\n",
    "        date = date_el.get_text()\n",
    "        home_score = match.find('span', class_='wcl-matchRowScore_fWR-Z wcl-isFinal_7U4ca event__score event__score--home').text\n",
    "        away_score = match.find('span', class_='wcl-matchRowScore_fWR-Z wcl-isFinal_7U4ca event__score event__score--away').text\n",
    "\n",
    "        \n",
    "        day_month = date.split()[0].replace('.', '')\n",
    "        time_part = date.split()[1]\n",
    "        \n",
    "        day = int(day_month[:2])\n",
    "        month = int(day_month[2:])\n",
    "        year = first_year if month >= 8 else second_year\n",
    "\n",
    "        match_day = f\"{year}-{month:02d}-{day:02d}\"\n",
    "            \n",
    "\n",
    "        dates.append(date)\n",
    "        season.append({\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'match_day': match_day,\n",
    "            'time': time_part,\n",
    "            'home_score': home_score,\n",
    "            'away_score': away_score\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(season), dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fa51725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dates = get_matches()\n",
    "# df.to_csv('epl_fixtures_2023_2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c966912e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>match_day</th>\n",
       "      <th>time</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Everton</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>16:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brentford</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>16:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>Man Utd</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burnley</td>\n",
       "      <td>Nottm Forest</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>16:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>16:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>Luton</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Everton</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Sheff Utd</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Nottm Forest</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>12:30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Burnley</td>\n",
       "      <td>Man City</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_team       away_team   match_day   time home_score away_score\n",
       "0      Arsenal         Everton  2024-05-19  16:00          2          1\n",
       "1    Brentford       Newcastle  2024-05-19  16:00          2          4\n",
       "2     Brighton         Man Utd  2024-05-19  16:00          0          2\n",
       "3      Burnley    Nottm Forest  2024-05-19  16:00          1          2\n",
       "4      Chelsea     Bournemouth  2024-05-19  16:00          2          1\n",
       "..         ...             ...         ...    ...        ...        ...\n",
       "375   Brighton           Luton  2023-08-12  15:00          4          1\n",
       "376    Everton          Fulham  2023-08-12  15:00          0          1\n",
       "377  Sheff Utd  Crystal Palace  2023-08-12  15:00          0          1\n",
       "378    Arsenal    Nottm Forest  2023-08-12  12:30          2          1\n",
       "379    Burnley        Man City  2023-08-11  20:00          0          3\n",
       "\n",
       "[380 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d10c1b1",
   "metadata": {},
   "source": [
    "* I was able to successfully extract the data, however there are some parts that still need attention\n",
    "* The date column has no year associated\n",
    "\n",
    "    ## <h4>Points to work on</h4>\n",
    "\n",
    "* Add year and separate time from dates\n",
    "* Refactor the function to iterate through all seasons\n",
    "* Append all the data in one complete spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74558440",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year = 2023\n",
    "second_year = 2024\n",
    "\n",
    "match_day = []\n",
    "\n",
    "for date in dates:\n",
    "    day_month = date.split()[0].replace('.', '')\n",
    "    time_part = date.split()[1]\n",
    "    day = int(day_month[:2])\n",
    "    month = int(day_month[2:])\n",
    "    year = first_year if month >= 8 else second_year\n",
    "\n",
    "    match_day.append(f\"{year}-{month}-{day}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1503c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epl_fixtures(first_year, second_year):\n",
    "    soup = get_raw_data(f'https://www.livesport.com/uk/football/england/premier-league-{first_year}-{second_year}/results/')\n",
    "    fixtures = soup.find('div', class_='sportName soccer')\n",
    "    all_div = []\n",
    "    for div in fixtures.find_all('div', recursive=False):\n",
    "        classes = div.get('class')\n",
    "        if not 'event__match' in classes:\n",
    "            continue\n",
    "        all_div.append(div)\n",
    "\n",
    "    season = []\n",
    "    dates = []\n",
    "    for match in all_div:\n",
    "        home_team = match.find('div', class_='wcl-participant_bctDY event__homeParticipant').text\n",
    "        away_team = match.find('div', class_='wcl-participant_bctDY event__awayParticipant').text\n",
    "        date_el = match.find('div', class_='event__time')\n",
    "        date = date_el.get_text()\n",
    "        home_score = match.find('span', class_='wcl-matchRowScore_fWR-Z wcl-isFinal_7U4ca event__score event__score--home').text\n",
    "        away_score = match.find('span', class_='wcl-matchRowScore_fWR-Z wcl-isFinal_7U4ca event__score event__score--away').text\n",
    "\n",
    "        \n",
    "        day_month = date.split()[0].replace('.', '')\n",
    "        time_part = date.split()[1]\n",
    "        \n",
    "        day = int(day_month[:2])\n",
    "        month = int(day_month[2:])\n",
    "        year = first_year if month >= 8 else second_year\n",
    "\n",
    "        match_day = f\"{year}-{month:02d}-{day:02d}\"\n",
    "            \n",
    "        season.append({\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'match_day': match_day,\n",
    "            'time': time_part,\n",
    "            'home_score': home_score,\n",
    "            'away_score': away_score\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a324ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed season 2023-2024\n",
      "Completed season 2022-2023\n",
      "Completed season 2021-2022\n",
      "Completed season 2020-2021\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     10\u001b[39m     time.sleep(\u001b[32m3\u001b[39m)  \u001b[38;5;66;03m# Pause to avoid overwhelming the server\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     df = \u001b[43mget_epl_fixtures\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_year\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Add a season column to identify which season each match belongs to\u001b[39;00m\n\u001b[32m     13\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mseason\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_year\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mget_epl_fixtures\u001b[39m\u001b[34m(first_year, second_year)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_epl_fixtures\u001b[39m(first_year, second_year):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     soup = \u001b[43mget_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://www.livesport.com/uk/football/england/premier-league-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfirst_year\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msecond_year\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/results/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     fixtures = soup.find(\u001b[33m'\u001b[39m\u001b[33mdiv\u001b[39m\u001b[33m'\u001b[39m, class_=\u001b[33m'\u001b[39m\u001b[33msportName soccer\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m     all_div = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mget_raw_data\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     16\u001b[39m     link.click()\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Wait for the link to become stale (content expanded)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstaleness_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Ignore if already expanded or error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\archb\\.conda\\envs\\pg\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:137\u001b[39m, in \u001b[36mWebDriverWait.until\u001b[39m\u001b[34m(self, method, message)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m time.monotonic() > end_time:\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m._poll)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "initial_year = 2023\n",
    "final_year = 1901\n",
    "\n",
    "all_seasons = []\n",
    "missing_seasons = []\n",
    "\n",
    "while initial_year > final_year:\n",
    "    try:\n",
    "        time.sleep(3)  # Pause to avoid overwhelming the server\n",
    "        df = get_epl_fixtures(initial_year, initial_year + 1)\n",
    "        # Add a season column to identify which season each match belongs to\n",
    "        df['season'] = f\"{initial_year}-{initial_year + 1}\"\n",
    "        all_seasons.append(df)\n",
    "        print(f\"Completed season {initial_year}-{initial_year + 1}\")\n",
    "    except Exception as e:\n",
    "        missing_seasons.append(f\"{initial_year}-{initial_year + 1}\")\n",
    "        print(f\"Error processing season {initial_year}-{initial_year + 1}: {e}\")\n",
    "    \n",
    "    initial_year -= 1\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "if all_seasons:\n",
    "    complete_df = pd.concat(all_seasons, ignore_index=True)\n",
    "    print(f\"Total matches collected: {len(complete_df)}\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    complete_df.to_csv('epl_all_seasons.csv', index=False)\n",
    "    print(\"Data saved to epl_all_seasons.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282f4e4",
   "metadata": {},
   "source": [
    "* For simplicity sake, I am going to write a python script for scrapping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2414308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_fixtures.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_fixtures.py\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "\n",
    "def get_raw_data(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, \"live-table\")))\n",
    "\n",
    "    while True:\n",
    "        # Find all current \"Show more\" links\n",
    "        show_more_links = driver.find_elements(By.XPATH, \"//span[contains(text(), 'Show more matches')]/parent::a\")\n",
    "        if not show_more_links:\n",
    "            break  # No more links to click\n",
    "\n",
    "        for link in show_more_links:\n",
    "            try:\n",
    "                # Scroll to the link to ensure it's visible\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", link)\n",
    "                link.click()\n",
    "                # Wait for the link to become stale (content expanded)\n",
    "                WebDriverWait(driver, 5).until(EC.staleness_of(link))\n",
    "            except Exception:\n",
    "                pass  # Ignore if already expanded or error\n",
    "\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "    return soup\n",
    "\n",
    "def get_epl_fixtures(first_year, second_year):\n",
    "    soup = get_raw_data(f'https://www.livesport.com/uk/football/england/premier-league-{first_year}-{second_year}/results/')\n",
    "    fixtures = soup.find('div', class_='sportName soccer')\n",
    "    all_div = []\n",
    "    for div in fixtures.find_all('div', recursive=False):\n",
    "        classes = div.get('class')\n",
    "        if not 'event__match' in classes:\n",
    "            continue\n",
    "        all_div.append(div)\n",
    "\n",
    "    season = []\n",
    "    dates = []\n",
    "    for match in all_div:\n",
    "        home_team = match.find('div', class_='wcl-participant_bctDY event__homeParticipant').text\n",
    "        away_team = match.find('div', class_='wcl-participant_bctDY event__awayParticipant').text\n",
    "        date_el = match.find('div', class_='event__time')\n",
    "        date = date_el.get_text()\n",
    "        home_score = match.find('span', class_='wcl-matchRowScore_fWR-Z wcl-isFinal_7U4ca event__score event__score--home').text\n",
    "        away_score = match.find('span', class_='wcl-matchRowScore_fWR-Z wcl-isFinal_7U4ca event__score event__score--away').text\n",
    "\n",
    "        \n",
    "        day_month = date.split()[0].replace('.', '')\n",
    "        time_part = date.split()[1]\n",
    "        \n",
    "        day = int(day_month[:2])\n",
    "        month = int(day_month[2:])\n",
    "        year = first_year if month >= 8 else second_year\n",
    "\n",
    "        match_day = f\"{year}-{month:02d}-{day:02d}\"\n",
    "            \n",
    "        season.append({\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'match_day': match_day,\n",
    "            'time': time_part,\n",
    "            'home_score': home_score,\n",
    "            'away_score': away_score\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c41fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed season 2023-2024\n",
      "Completed season 2022-2023\n",
      "Completed season 2021-2022\n",
      "Completed season 2020-2021\n",
      "Completed season 2019-2020\n",
      "Completed season 2018-2019\n",
      "Completed season 2017-2018\n",
      "Completed season 2016-2017\n",
      "Completed season 2015-2016\n",
      "Completed season 2014-2015\n",
      "Completed season 2013-2014\n",
      "Completed season 2012-2013\n",
      "Completed season 2011-2012\n",
      "Completed season 2010-2011\n",
      "Completed season 2009-2010\n",
      "Completed season 2008-2009\n",
      "Completed season 2007-2008\n",
      "Completed season 2006-2007\n",
      "Completed season 2005-2006\n",
      "Completed season 2004-2005\n",
      "Completed season 2003-2004\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from get_fixtures import get_epl_fixtures\n",
    "initial_year = 2023\n",
    "final_year = 1901\n",
    "\n",
    "all_seasons = []\n",
    "missing_seasons = []\n",
    "\n",
    "while initial_year > final_year:\n",
    "    try:\n",
    "        time.sleep(3)  # Pause to avoid overwhelming the server\n",
    "        df = get_epl_fixtures(initial_year, initial_year + 1)\n",
    "        # Add a season column to identify which season each match belongs to\n",
    "        df['season'] = f\"{initial_year}-{initial_year + 1}\"\n",
    "        all_seasons.append(df)\n",
    "        print(f\"Completed season {initial_year}-{initial_year + 1}\")\n",
    "    except Exception as e:\n",
    "        missing_seasons.append(f\"{initial_year}-{initial_year + 1}\")\n",
    "        print(f\"Error processing season {initial_year}-{initial_year + 1}: {e}\")\n",
    "    \n",
    "    initial_year -= 1\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "# if all_seasons:\n",
    "#     complete_df = pd.concat(all_seasons, ignore_index=True)\n",
    "#     print(f\"Total matches collected: {len(complete_df)}\")\n",
    "    \n",
    "#     # Save to CSV\n",
    "#     complete_df.to_csv('epl_all_seasons.csv', index=False)\n",
    "#     print(\"Data saved to epl_all_seasons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd78f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
